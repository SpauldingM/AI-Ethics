# AI-Ethics

## Policy Snippet:
The use of AI tools in our security operations help monitor our systems activity and alert of potential threats, such as unusual logins, out of the ordinary network traffic and file transfers that look suspicious. When an alert is triggered, it will include an explanation for what has happened to trigger it and why. 

A security analyst would be trained and in the loop, letting them review, confirm or override the alerts. If you believe the alert is incorrect, you may submit an appeal with the help desk. All appeals will be reviewed within a week of submission and a written response will be provided.

Only the minimum and necessary data will be collected needed for threat detection. All sensitive information will be redacted and the data that is kept will be retained until investigation is complete.

Our AI system will be retrained quarterly and the policies will be reviewed twice a year to ensure reliability and transparency. We will track how accurate the system is, how many false positives it detects and response time.

## Controls & Metrics:
1. Human in the loop review for critical alerts (100% coverage)
2. Appeal processes acknowledged within a day and resolved within five business days
3. Bias and accuracy testing performed quarterly on diverse datasets.
4. Maintain false postive/negative rates at or below five percent
   
## Justifications:
These controls address two of the major risks that are identified, Biases and false positives/negatives. Subgroup evaluation ensures that the impacts are proportionate no matter the groups while the human in the loops reviews ensures that actual human beings make the final decisions on critical actions that were once flagged by AI. Setting metrics on False positive/negatives and timelines on appeals to be efficient in not only how fair but how transparent the final decision is. Regular training and policy reviews ensure the system adapts to threats without sacrificing accountability.

## Evidence Links:
[Weekly Report](weekly-report-week-6.pdf)

[AI Security policy](AI-Use-In-Security-Policy.pdf)

## Reflection:
One thing I would love to go back and visit is the metric on maintaining the five percent for False positives/negatives. While a wonderful idea when it comes down to accountability, it would be a difficult task as maintain that with frequent retraining and higher costs as it would reduce the tolerance for other threats. I might set the thresholds a bit differently as an impact of missing an attack would be much greater then handling another alert. 
